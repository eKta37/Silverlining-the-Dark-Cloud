{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiLabel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FigIjDbVpLP",
        "outputId": "7f6ce6da-c752-442e-8a4c-ca18e6e23f24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIUqbeE3V3Cm",
        "outputId": "86032702-acaf-40fe-fffd-4f782713a107"
      },
      "source": [
        "cd gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axwazinGV3Fp",
        "outputId": "2ad1b908-c0be-4965-b1e4-afa82bd653a0"
      },
      "source": [
        "cd MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvzg6ITEV3IK",
        "outputId": "89a9e503-0677-45ff-d7e9-33234aeef2ec"
      },
      "source": [
        "cd Colab datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAgPHpiTV3J1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as mplot\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "# from skmultilearn.problem_transform import LabelPowerset\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "a6H-zy0NV3Pd",
        "outputId": "260a8973-89d1-43ec-b0e1-7c6bb9353ee3"
      },
      "source": [
        "Data = pd.read_csv(\"multilable_dataset.csv\")\n",
        "Data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentText</th>\n",
              "      <th>facts</th>\n",
              "      <th>hypocrisy</th>\n",
              "      <th>warning</th>\n",
              "      <th>affiliation</th>\n",
              "      <th>denouncing</th>\n",
              "      <th>humor</th>\n",
              "      <th>positive_tone</th>\n",
              "      <th>hostile_language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kind god hates people curses kind people belie...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>question comment racist jews smartest group pe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>israel fail nothing new israel rebellious nati...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>god damned ignorant little prick doesnt know a...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shit may cooler police brutality people assumi...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         commentText  ...  hostile_language\n",
              "0  kind god hates people curses kind people belie...  ...                 0\n",
              "1  question comment racist jews smartest group pe...  ...                 0\n",
              "2  israel fail nothing new israel rebellious nati...  ...                 0\n",
              "3  god damned ignorant little prick doesnt know a...  ...                 1\n",
              "4  shit may cooler police brutality people assumi...  ...                 0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUjLGgFQauYP"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "trainA, trainB = train_test_split(Data, test_size=0.50, shuffle=True)\n",
        "train_dataA = trainA['commentText'].values\n",
        "train_dataB = trainB['commentText'].values\n",
        " \n",
        "labels=['facts', 'hypocrisy', 'warning', 'affiliation', 'denouncing', 'humor', 'positive_tone', 'hostile_language']\n",
        "YTrainA = trainA[labels]\n",
        "YTrainB = trainB[labels]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKkSFbcchrFo"
      },
      "source": [
        "train, test = train_test_split(trainA, test_size=0.40, shuffle=True)\n",
        "train_data = train['commentText'].values\n",
        "test_data = test['commentText'].values\n",
        " \n",
        "labels=['facts', 'hypocrisy', 'warning', 'affiliation', 'denouncing', 'humor', 'positive_tone', 'hostile_language']\n",
        "YTrain = train[labels]\n",
        "YTest = test[labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y4wd-IZbLrJ"
      },
      "source": [
        "vect = CountVectorizer(min_df=2, ngram_range=(1, 3))\n",
        "XTrain = vect.fit(train_data).transform(train_data)\n",
        "XTest = vect.transform(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05F_DXiWbUW8",
        "outputId": "1c6c30ab-a07a-44de-9a8f-c38ed9a3e5d7"
      },
      "source": [
        "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
        "print(\"XTrain : \\n{}\".format(repr(XTrain)))\n",
        "print(\"XTest : \\n{}\".format(repr(XTest)))\n",
        "print(\"Features : {}\".format(len(vect.get_feature_names())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 51811\n",
            "XTrain : \n",
            "<10297x51811 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 250248 stored elements in Compressed Sparse Row format>\n",
            "XTest : \n",
            "<6865x51811 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 115864 stored elements in Compressed Sparse Row format>\n",
            "Features : 51811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lexoe5uBWepj"
      },
      "source": [
        "### OneVsRest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cssyt9oWbgs4",
        "outputId": "6e777268-788f-4699-d668-9c17ba59d539"
      },
      "source": [
        "categories = list(Data.columns.values)\n",
        "categories = categories[1:]\n",
        "print(categories)\n",
        "\n",
        "LogReg_pipeline = Pipeline([\n",
        "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
        "            ])\n",
        "lst = []\n",
        "for category in categories:\n",
        "    # Training logistic regression model on train data\n",
        "    LogReg_pipeline.fit(XTrain, YTrain[category])\n",
        "    \n",
        "    # calculating test accuracy\n",
        "    YPred = LogReg_pipeline.predict(XTest)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(YTest[category], YPred).ravel()\n",
        "    recall = tp/(tp+fn)\n",
        "    precision = tp/(tp+fp)\n",
        "    accuracy = (tn+tp)/(tn+tp+fp+fn)\n",
        "    f1_score = (2*recall*precision)/(recall+precision)\n",
        "\n",
        "    temp = [precision, recall, accuracy, f1_score]\n",
        "    lst.append(temp)\n",
        "\n",
        "    print('Test accuracy of {} is {}'.format(category, accuracy_score(YTest[category], YPred)))\n",
        "\n",
        "print()\n",
        "for i in range(len(lst)):\n",
        "  print(categories[i], lst[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['facts', 'hypocrisy', 'warning', 'affiliation', 'denouncing', 'humor', 'positive_tone', 'hostile_language']\n",
            "Test accuracy of facts is 0.9319737800436999\n",
            "Test accuracy of hypocrisy is 0.8906045156591406\n",
            "Test accuracy of warning is 0.9229424617625638\n",
            "Test accuracy of affiliation is 0.9258557902403496\n",
            "Test accuracy of denouncing is 0.8566642388929352\n",
            "Test accuracy of humor is 0.8782228696285507\n",
            "Test accuracy of positive_tone is 0.9149308084486526\n",
            "Test accuracy of hostile_language is 0.8182083029861617\n",
            "\n",
            "facts [0.8233695652173914, 0.4297872340425532, 0.9319737800436999, 0.5647716682199441]\n",
            "hypocrisy [0.8, 0.35546875, 0.8906045156591406, 0.4922244759972954]\n",
            "warning [0.8390804597701149, 0.3101983002832861, 0.9229424617625638, 0.45294725956566706]\n",
            "affiliation [0.8051282051282052, 0.25, 0.9258557902403496, 0.38153098420413123]\n",
            "denouncing [0.733983286908078, 0.39924242424242423, 0.8566642388929352, 0.5171736997055938]\n",
            "humor [0.8524173027989822, 0.30098831985624436, 0.8782228696285507, 0.4448871181938911]\n",
            "positive_tone [0.831353919239905, 0.4055619930475087, 0.9149308084486526, 0.545171339563863]\n",
            "hostile_language [0.8102189781021898, 0.7007055328629781, 0.8182083029861617, 0.7514934289127838]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4p7RcEgX5PD"
      },
      "source": [
        "### BinaryRelevance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs7nFxXuL9bq",
        "outputId": "660dcdc2-8559-4f8d-eb1f-ed0267198310"
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.3MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcIaXhc8cNA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db3b4f9-936b-4d3f-d4ee-f7270d8dc29d"
      },
      "source": [
        "\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# initialize binary relevance multi-label classifier\n",
        "# with a gaussian naive bayes base classifier\n",
        "classifier = BinaryRelevance(LogisticRegression())\n",
        "\n",
        "# train\n",
        "classifier.fit(XTrain, YTrain)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(XTest)\n",
        "accuracy_score(YTest,predictions)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(YTest, predictions).ravel()\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp)\n",
        "f1_score = (2*recall*precision)/(recall+precision)\n",
        "print(\"recall: \",recall,\"\\nprecision: \",precision,\"\\naccuracy: \",accuracy_score,\"\\nf1_score: \",f1_score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5299344501092498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMz4ybLpmN6O"
      },
      "source": [
        "### ClassifierChain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AuaYPbMV3Qo",
        "outputId": "edbfa28e-7bc9-4d96-d591-df5112defcaa"
      },
      "source": [
        "\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "\n",
        "# with a gaussian naive bayes base classifier\n",
        "classifier = ClassifierChain(LogisticRegression())\n",
        "\n",
        "# train\n",
        "classifier.fit(XTrain, YTrain)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(XTest)\n",
        "\n",
        "accuracy_score(YTest,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5962126729788784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCyuA18tWlV4",
        "outputId": "9d88ac25-2166-4321-d38b-448fff93b57f"
      },
      "source": [
        "\n",
        "# with a gaussian naive bayes base classifier\n",
        "classifier = ClassifierChain(DecisionTreeClassifier())\n",
        "\n",
        "# train\n",
        "classifier.fit(XTrain, YTrain)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(XTest)\n",
        "\n",
        "accuracy_score(YTest,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6211216314639476"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSgiEOKcmI-D"
      },
      "source": [
        "### LabelPowerset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmx2SPBMkm9M",
        "outputId": "11653a26-2043-4d1b-ef80-8616e0553f0d"
      },
      "source": [
        "# using Label Powerset\n",
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "# initialize label powerset multi-label classifier\n",
        "classifier = LabelPowerset(DecisionTreeClassifier())\n",
        "# train\n",
        "classifier.fit(XTrain, YTrain)\n",
        "# predict\n",
        "predictions = classifier.predict(XTest)\n",
        "# accuracy\n",
        "print(\"Accuracy = \",accuracy_score(YTest,predictions))\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.6773488710852149\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_bqPZWtl6sv",
        "outputId": "8ba924c1-d317-4c4c-ab39-774c69a81a53"
      },
      "source": [
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "# initialize label powerset multi-label classifier\n",
        "classifier = LabelPowerset(LogisticRegression(max_iter=250))\n",
        "# train\n",
        "classifier.fit(XTrain, YTrain)\n",
        "# predict\n",
        "predictions = classifier.predict(XTest)\n",
        "# accuracy\n",
        "print(\"Accuracy = \",accuracy_score(YTest,predictions))\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.7077931536780772\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}